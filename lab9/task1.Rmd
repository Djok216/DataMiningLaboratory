```{r}

data = read.csv('../data/train.csv')
data = data[-1]

```

```{r}
# k folding
k <- 6  # one partition for test and rest for train

folds <- sample(rep(1:k, length.out = nrow(data)))

split_data <- function(ith){
  if (ith > k || ith <= 0)
    stop("Inexistent partition")
  
  pelem <- which(folds == ith)
  return (list("test" = data[pelem, ], "train" = data[-pelem, ]))
}
```

```{r}
# decision tree classifier
library(rpart)
library(caret)

partition <- split_data(4)
test = partition$test
train = partition$train
tr <- rpart(formula=Cover_Type ~ ., data=train, method="class")
rpart.plot(tr, box.palette = 0)
printcp(tr)
cm <- table(test$Cover_Type, rpart.predict(tr, test, type="class"))
rownames(cm) <- paste("Actual", rownames(cm), sep = ":")
colnames(cm) <- paste("Pred", colnames(cm), sep = ":")
cm
sum(diag(cm)) / nrow(test)
```

```{r}
library(caret)
library(rpart.plot)

intrain <- createDataPartition(y = data$Cover_Type, p= 0.7, list = FALSE)
training <- data[intrain,]
testing <- data[-intrain,]
dim(training); dim(testing);

decisinStump(X=training$Elevation, Y=training$Id)
# trctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
# dtree_fit <- train(Cover_Type ~., data = training, method = "gbm",
#                    parms = list(split = "information"),
#                    trControl=trctrl,
#                    tuneLength = 10)
# test_pred <- predict(dtree_fit, newdata = testing, type="prob")
# print("\n")
# str(test_pred)
# str(as.vector(testing$Cover_Type))
# 
# 
# confusionMatrix(as.vector(testing$Cover_Type), as.vector(testing$Cover_Type))
names(getModelInfo())
```