```{r}
# train data
data = read.csv('../data/train.csv')
data = data[-1]
```

```{r}
# Mahalanobis distance 2D
for (i in 1:9) {
  name1 = colnames(data)[i]
  for (j in (i+1):10) {
    name2 = colnames(data)[j]
    hw = data.frame(name1=data[, i], name2=data[, j])
    ord = order(mahalanobis(hw, colMeans(hw), cov(hw)), decreasing=T)
    outlier = rep(F, nrow(hw))
    outlier[ord[1:100]] = T
    pch = outlier * 16
    plot(hw, pch=pch, xlab=name1, ylab=name2)
  }
}
```
```{r}
# Mahalanobis distance 3D
library(rgl)
name1 = colnames(data)[1]
name2 = colnames(data)[2]
name3 = colnames(data)[3]
hw = data.frame(name1=data[, 1], name2=data[, 2], name3=data[, 3])
ord = order(mahalanobis(hw, colMeans(hw), cov(hw)), decreasing=T)
outlier = rep(F, nrow(hw))
outlier[ord[1:100]] = T
col = outlier + 1
plot3d(hw$name1, hw$name2, hw$name3, type='s', col=col, xlab=name1, ylab=name2, zlab=name3)

```

```{r}
# autoencoders, init h2o and train/save model
library(h2o)
h2o.init(nthreads = -1)
data_hf = as.h2o(data)
features = setdiff(colnames(data_hf), "Cover_Type")
model_nn = h2o.deeplearning(x = features, 
                            training_frame = data_hf, 
                            model_id = 'autoencoder',
                            autoencoder = T,
                            ignore_const_cols = F,
                            seed = 57,
                            hidden = c(25, 10, 25),
                            epochs = 100,
                            activation = 'Tanh')
h2o.saveModel(model_nn, path='autoencoder', force = T)
model_nn
```

```{r}
# load Autoencoder model and identify outliers
library(h2o)
library(dplyr)
library(ggplot2)
h2o.init(nthreads = -1)
data_hf = as.h2o(data)
model_nn = h2o.loadModel("autoencoder/autoencoder")
anomaly = h2o.anomaly(model_nn, data_hf) %>%
  as.data.frame() %>%
  tibble::rownames_to_column() %>%
  mutate(Cover_Type = as.vector(data$Cover_Type))

mean_mse = anomaly %>%
  group_by(Cover_Type) %>%
  summarise(mean = mean(Reconstruction.MSE))

ggplot(anomaly, aes(x = as.numeric(rowname), y = Reconstruction.MSE, color = as.factor(Cover_Type))) +
  geom_point(alpha = 0.3) +
  geom_hline(data = mean_mse, aes(yintercept = mean, color = as.factor(Cover_Type))) +
  scale_color_brewer(palette = "Set1") +
  labs(x = "instance number",
       color = "Cover_Type")

```

```{r}
# LOF
library(dbscan)
for (i in 1:9) {
  name1 = colnames(data)[i]
  for (j in (i+1):10) {
    name2 = colnames(data)[j]
    lof_data = data.frame(name1 = data[, i], name2 = data[, j])
    loff = lof(lof_data, k = 5)
    plot(lof_data, pch = ".", main = "LOF (k=3)", xlab=name1, ylab=name2)
    points(lof_data, cex = (loff-1)*3, pch = 1, col="red")
    text(lof_data[loff>2,], labels = round(loff, 1)[loff>2], pos = 3)
  }
}
```


```{r}
# Isolation Forest
# library(devtools)
# install_github("Zelazny7/isofor")
library(isofor)
data = read.csv('../data/train.csv')
data = data[-1]

for (i in 1:9) {
  name1 = colnames(data)[i]
  for (j in (i+1):10) {
    name2 = colnames(data)[j]
    hw = data.frame(name1=data[, i], name2=data[, j])
    mod = iForest(X = hw, 200, 32)
    p = predict(mod, hw)
    col = ifelse(p > quantile(p, 0.95), "red", "blue")
    plot(hw, col=col, xlab=name1, ylab=name2)
  }
}
```

```{r}

library(mrfDepth)
data = read.csv('../data/train.csv')
# data = data[-1]
selected_data = data[, c('Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 
                         'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 
                         'Hillshade_9am', 'Hillshade_Noon', 'Horizontal_Distance_To_Fire_Points')
                     ]

result = outlyingness(x = selected_data)
outliers = which(!result$flagX)
plot(selected_data)
head(selected_data$outliers)
points(selected_data[outliers,], col = "red")
```


